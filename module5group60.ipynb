{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Warmup. As a warmup, write code to collect statistics about word frequencies in the two languages. Print the 10 most frequent words in each language.\n",
    "\n",
    "If you're working with Python, using a CounterLinks to an external site. is probably the easiest solution.\n",
    "\n",
    "Let's assume that we pick a word completely randomly from the European parliament proceedings. According to your estimate, what is the probability that it is speaker? What is the probability that it is zebra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process file and count occurrences of words, also returns a list of words\n",
    "def setup(file_path):\n",
    "    word_counter = Counter()\n",
    "    to_remove = ['apos', '.']\n",
    "    # Open file and iterate over lines\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split line into words\n",
    "            #line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "            \n",
    "            words = line.split()\n",
    "            words = [word.lower() for word in words if word not in string.punctuation]\n",
    "            # Update Counter with words\n",
    "            word_counter.update(words)\n",
    "  \n",
    "    with open(file_path, 'r') as file:\n",
    "        file_to_list = file.read().split('\\n')\n",
    "        for i, sentence in enumerate(file_to_list):\n",
    "            words = sentence.split()\n",
    "            words = [word.lower() for word in words if word not in string.punctuation]\n",
    "            file_to_list[i] = ' '.join(words)\n",
    "            \n",
    "    return word_counter, file_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_de_file_path = 'dat410_europarl/europarl-v7.de-en.lc.en'\n",
    "german_file_path = 'dat410_europarl/europarl-v7.de-en.lc.de'\n",
    "\n",
    "english_de_word_counter, english_de_list = setup(english_de_file_path)\n",
    "german_en_word_counter, german_en_list = setup(german_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sv_file_path = 'dat410_europarl/europarl-v7.sv-en.lc.en'\n",
    "swedish_file_path = 'dat410_europarl/europarl-v7.sv-en.lc.sv'\n",
    "\n",
    "english_sv_word_counter, english_sv_list = setup(english_sv_file_path)\n",
    "swedish_en_word_counter, swedish_en_list = setup(swedish_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_fr_file_path = 'dat410_europarl/europarl-v7.fr-en.lc.en'\n",
    "french_en_file_path = 'dat410_europarl/europarl-v7.fr-en.lc.fr'\n",
    "\n",
    "english_fr_word_counter, english_fr_list = setup(english_fr_file_path)\n",
    "french_en_word_counter, french_en_list = setup(french_en_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 58790), ('of', 28406), ('to', 26842), ('and', 21459), ('in', 18485), ('is', 13331), ('that', 13219), ('a', 13090), ('we', 9936), ('this', 9916)]\n",
      "[('die', 10521), ('der', 9374), ('und', 7028), ('in', 4175), ('zu', 3168), ('den', 2976), ('wir', 2863), ('daß', 2738), ('ich', 2670), ('das', 2669)]\n",
      "[('att', 9181), ('och', 7038), ('i', 5949), ('det', 5687), ('som', 5028), ('för', 4959), ('av', 4013), ('är', 3840), ('en', 3724), ('vi', 3211)]\n",
      "[('&apos;', 16729), ('de', 14520), ('la', 9746), ('et', 6619), ('l', 6536), ('le', 6174), ('les', 5585), ('à', 5500), ('des', 5232), ('que', 4797)]\n"
     ]
    }
   ],
   "source": [
    "#merge the english word counters\n",
    "english_word_counter = english_de_word_counter + english_sv_word_counter + english_fr_word_counter\n",
    "\n",
    "print(english_word_counter.most_common(10))\n",
    "print(german_en_word_counter.most_common(10))\n",
    "print(swedish_en_word_counter.most_common(10))\n",
    "print(french_en_word_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# P(word in all languages)\n",
    "def probability_of_word(word, wordcounters):\n",
    "    return sum([(word_counter[word]) for word_counter in wordcounters])/ sum([sum(word_counter.values()) for word_counter in wordcounters])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Speaker\" all languages 2.1349591802274315e-05\n",
      "\"Speaker\" in English 4.23327120259538e-05\n",
      "\"The\" all languages 0.038048854335616875\n",
      "\"The\" in English 0.07541636787896436\n",
      "\"The\" in french 4.799909238079862e-05\n",
      "\"The\" in German 2.9430065755175486e-05\n",
      "\"Zebra\" all languages 0.0\n",
      "\"Zebra\" in English 0.0\n"
     ]
    }
   ],
   "source": [
    "# Some examples of word probabilities\n",
    "print(\"\\\"Speaker\\\" all languages\", probability_of_word('speaker', [english_word_counter, swedish_en_word_counter, german_en_word_counter, french_en_word_counter]))\n",
    "print(\"\\\"Speaker\\\" in English\", probability_of_word('speaker', [english_word_counter]))\n",
    "print(\"\\\"The\\\" all languages\",probability_of_word('the', [english_word_counter, swedish_en_word_counter, german_en_word_counter, french_en_word_counter]))\n",
    "print(\"\\\"The\\\" in English\",probability_of_word('the', [english_word_counter]))\n",
    "print(\"\\\"The\\\" in french\",probability_of_word('theatos', [swedish_en_word_counter]))\n",
    "print(\"\\\"The\\\" in German\",probability_of_word('the', [german_en_word_counter]))\n",
    "print(\"\\\"Zebra\\\" all languages\",probability_of_word('zebra', [english_word_counter, swedish_en_word_counter, german_en_word_counter, french_en_word_counter]))\n",
    "print(\"\\\"Zebra\\\" in English\",probability_of_word('zebra', [english_word_counter]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a bigram model and use it to calculate the probability of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement a bigram model\n",
    "def count_bigrams(language_list):\n",
    "    bigram_counter = Counter()\n",
    "\n",
    "    # Open file and iterate over lines\n",
    "    for sentence in language_list:\n",
    "        # Split sentence into words\n",
    "        words = sentence.split(' ')\n",
    "        words = [word.lower() for word in words]\n",
    "        \n",
    "        # Update Counter with words\n",
    "        bigrams = [(words[i], words[i+1]) for i in range(len(words)-1)]\n",
    "        bigram_counter.update(bigrams)\n",
    "\n",
    "    return bigram_counter\n",
    "\n",
    "# nr such bigrams/ all other bigrams starting with the same word\n",
    "def probability_of_bigram_in_language(bigram, bigram_counter, word_counter):\n",
    "    return bigram_counter[bigram] / word_counter[bigram[0]] if word_counter[bigram[0]] > 0 else 0\n",
    "\n",
    "#probability of sentence is the product of the probabilities of the bigrams and the probability of the word itself\n",
    "def probability_of_sentence(sentence, bigram_counter, word_counter):\n",
    "    words = sentence.split()\n",
    "    words = [word.lower() for word in words]\n",
    "    bigrams = [(words[i], words[i+1]) for i in range(len(words)-1)]\n",
    "    probabilities = []\n",
    "    #probabilities.append(probability_of_word(words[0], word_counter))\n",
    "    for bigram in bigrams:\n",
    "        # If the word doesn't exist yet, we assume a very low probability\n",
    "        prob = probability_of_bigram_in_language(bigram, bigram_counter, word_counter)\n",
    "        #probability_of_word(bigram[1], [word_counter])\n",
    "     \n",
    "        probabilities.append(prob if prob > 0.000000001 else 0.000001)\n",
    "        #probabilities.append(prob if prob > 0.1 else 0.1)\n",
    "\n",
    "    return np.prod(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of \"The speaker is speaking.\" in English 4.5804953347655015e-12\n",
      "Probability of \"The speaker is speaking.\" in German 9.999999999999999e-19\n",
      "Probability of \"Of the speaker\" in English 1.6186135072199902e-05\n",
      "Probability of \"The speaker is speaking Gobbledygook\" in English 4.580495334765501e-18\n",
      "Probability of long sentence in English 0.0\n"
     ]
    }
   ],
   "source": [
    "#use it to compute the probability of a short sentence\n",
    "english_de_bigram_counter = count_bigrams(english_de_list)\n",
    "print(\"Probability of \\\"The speaker is speaking.\\\" in English\", probability_of_sentence(\"The speaker is speaking.\", english_de_bigram_counter, english_de_word_counter))\n",
    "print(\"Probability of \\\"The speaker is speaking.\\\" in German\", probability_of_sentence(\"The speaker is speaking.\", count_bigrams(german_en_list), german_en_word_counter))\n",
    "print(\"Probability of \\\"Of the speaker\\\" in English\", probability_of_sentence(\"Of the speaker\", english_de_bigram_counter, english_de_word_counter))\n",
    "\n",
    "#What happens if you try to compute the probability of a sentence that contains a word that did not appear in the training texts? \n",
    "print(\"Probability of \\\"The speaker is speaking Gobbledygook\\\" in English\", probability_of_sentence(\"The speaker is speaking Gobbledygook\", english_de_bigram_counter, english_de_word_counter))\n",
    "\n",
    "# And what happens if your sentence is very long (e.g. 100 words or more)? \n",
    "long_sentence = \"The case of Alexander Nikitin has garnered significant attention due to its complex legal implications and broader implications for environmental activism Alexander Nikitin a former naval officer turned environmental activist found himself embroiled in a legal battle with the Russian government over allegations of espionage and divulging state secrets Nikitin's involvement in environmental organizations particularly his work with the Bellona Foundation raised concerns among Russian authorities leading to his arrest and subsequent trial The case sparked international outcry with human rights organizations and environmental activists rallying behind Nikitin viewing his prosecution as an attempt to silence dissent and undermine environmental advocacy Despite facing immense pressure and legal challenges Nikitin persevered ultimately vindicated when the charges against him were dropped The case of Alexander Nikitin serves as a poignant reminder of the importance of protecting environmental activists' rights and the need for robust legal safeguards to uphold freedom of speech and environmental advocacy\"\n",
    "print(\"Probability of long sentence in English\", probability_of_sentence(long_sentence, english_de_bigram_counter, english_de_word_counter))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now estimate the parameters of the translation model P(f|e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give t values only to those f and e which are in the same indexed sentences are needed\n",
    "# Initialize t(f|e) randomly\n",
    "def initialize_parameters(source_list, target_list):\n",
    "    t_parameters = {}\n",
    "    for i in range(len(source_list)):\n",
    "        sentence1 = source_list[i].split(' ')\n",
    "        sentence2 = target_list[i].split(' ')\n",
    "        for word1 in sentence1:\n",
    "            if word1 not in t_parameters:\n",
    "                t_parameters[word1] = {}\n",
    "            for word2 in sentence2:\n",
    "                if word2 not in t_parameters[word1]:\n",
    "                    t_parameters[word1][word2] = np.random.rand()\n",
    "    return t_parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimation algorithm for IBM model 1\n",
    "def EM(list_language1, list_language2):\n",
    "   \n",
    "    #initialize t(e|f) uniformly\n",
    "    t = initialize_parameters(list_language1, list_language2)\n",
    "    print('initialization done')\n",
    "\n",
    "\n",
    "    # 10 iterations of the EM algorithm\n",
    "    for i in range(10):\n",
    "        #set count(e|f) to 0 for all e,f\n",
    "        count = {}\n",
    "        for j in range(len(list_language1)):\n",
    "            sentence1 = list_language1[j].split(' ')\n",
    "            sentence2 = list_language2[j].split(' ')\n",
    "            for word1 in sentence1:\n",
    "                if word1 not in count:\n",
    "                    count[word1] = {}\n",
    "                for word2 in sentence2:\n",
    "                    count[word1][word2] = 0\n",
    "        \n",
    "        #set count(f) to 0 for all f\n",
    "        total = {}\n",
    "        for sentence2 in list_language2:\n",
    "            for word2 in sentence2.split(' '):\n",
    "                total[word2] = 0\n",
    "\n",
    "        #for all sentence pairs (e_s,f_s)\n",
    "        for j in range(len(list_language1)):\n",
    "            sentence1 = list_language1[j].split(' ')\n",
    "            sentence2 = list_language2[j].split(' ')\n",
    "            #for all words e in e_s\n",
    "            for word1 in sentence1:\n",
    "                denominator = 0\n",
    "                temp_counts = {}\n",
    "                #for all words f in f_s\n",
    "                for word2 in sentence2:\n",
    "                    denominator += t[word1][word2]\n",
    "                    temp_counts[word2] = t[word1][word2]\n",
    "\n",
    "                if denominator > 0:\n",
    "                    for word2 in sentence2:\n",
    "                        count[word1][word2] += temp_counts[word2]/denominator\n",
    "                        total[word2] += temp_counts[word2]/denominator\n",
    "        #for all f in F\n",
    "        for j in range(len(list_language1)):\n",
    "            sentence1 = list_language1[j].split(' ')\n",
    "            sentence2 = list_language2[j].split(' ')\n",
    "            #for all e in E\n",
    "            for word1 in sentence1:\n",
    "                #t(e|f) = count(e|f)/total(f)\n",
    "                for word2 in sentence2:\n",
    "                    if total[word2] > 0:\n",
    "                        t[word1][word2] = count[word1][word2]/total[word2]\n",
    "\n",
    "        #print for german the ten words 'european' is most likely to be translated to\n",
    "        word_to_translate = 'european'\n",
    "        if word_to_translate in t:\n",
    "            # Sort the target dictionary items based on values in descending order\n",
    "            sorted_target_items = sorted(t[word_to_translate].items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "            # Print the top 10 words\n",
    "            print(f\"{word_to_translate}: {sorted_target_items[:10]}\")\n",
    "        else:\n",
    "            print(f\"{word_to_translate} not found in the dictionary.\")\n",
    "        print('iteration', i, 'done')\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization done\n",
      "european: [('zwei-klassen-gesellschaft', 0.17768634714976164), ('fbi', 0.16916896958119834), ('flugsicherung', 0.1607652312477656), ('grenzenlos', 0.15215617209540824), ('csu-europaabgeordneten', 0.15078337929486102), ('aufrechterhalten', 0.147624136070217), ('funktionsfähigkeit', 0.1372640944380807), ('zentraler', 0.13503498832778854), ('kulturraumes', 0.1318015910046665), ('botschaften', 0.12939807660288574)]\n",
      "iteration 0 done\n",
      "european: [('europäischer', 0.17794985173252004), ('mitteleuropas', 0.17768655741629086), ('funktionsfähigkeit', 0.15640529098798506), ('nordeuropäischer', 0.15428607375227596), ('fbi', 0.15411094527079552), ('zentraler', 0.14445579068280814), ('aufrechterhalten', 0.13730133215826335), ('grenzenlos', 0.13529870938773148), ('rechtshängig', 0.13462078724479248), ('flugsicherung', 0.13291707468698552)]\n",
      "iteration 1 done\n",
      "european: [('europäischer', 0.3958234864454802), ('europäisches', 0.24108895437649797), ('europäischen', 0.23486666979191687), ('mitteleuropas', 0.2328637801294693), ('nordeuropäischer', 0.20088030334501483), ('bekennen', 0.17817836042476537), ('union', 0.17757120451052902), ('totale', 0.1744917497270747), ('europäische', 0.16885732560861688), ('europawahlen', 0.16686811238427843)]\n",
      "iteration 2 done\n",
      "european: [('europäischer', 0.5721508602674543), ('europäisches', 0.4446364093420641), ('europäischen', 0.444081601803278), ('europäische', 0.4392197954447189), ('mitteleuropas', 0.27305476006034046), ('nordeuropäischer', 0.2505976758191812), ('europawahlen', 0.2501129580034255), ('totale', 0.24655479757928686), ('bekennen', 0.21247626945164821), ('union', 0.20500524199806894)]\n",
      "iteration 3 done\n",
      "european: [('europäischer', 0.6826447475343888), ('europäische', 0.6495971888791611), ('europäischen', 0.6162270738442338), ('europäisches', 0.5934619813359883), ('europawahlen', 0.3219461340128755), ('europäisch', 0.31331727546304194), ('totale', 0.31190961427602093), ('mitteleuropas', 0.2896720795889269), ('nordeuropäischer', 0.2858584519597688), ('csu-europagruppe', 0.24112393973958166)]\n",
      "iteration 4 done\n",
      "european: [('europäische', 0.770736323059129), ('europäischer', 0.7500289498755571), ('europäischen', 0.7314954032794847), ('europäisches', 0.6797644706547619), ('europäisch', 0.42882620348571066), ('europawahlen', 0.36880975187553555), ('totale', 0.3547202075248356), ('nordeuropäischer', 0.3068527347591061), ('mitteleuropas', 0.2982500340123938), ('europäischsten', 0.2742523585874306)]\n",
      "iteration 5 done\n",
      "european: [('europäische', 0.8401263264272513), ('europäischen', 0.8024127320320834), ('europäischer', 0.7911157999570396), ('europäisches', 0.7273726545534872), ('europäisch', 0.5032777827483101), ('europawahlen', 0.3951012936512748), ('totale', 0.3692116833903287), ('nordeuropäischer', 0.31837424730164665), ('mitteleuropas', 0.3019172395656935), ('europäischsten', 0.29499555917266457)]\n",
      "iteration 6 done\n",
      "european: [('europäische', 0.8820840686700034), ('europäischen', 0.8469416307074965), ('europäischer', 0.816820116546359), ('europäisches', 0.7535296958464215), ('europäisch', 0.5482058549821616), ('europawahlen', 0.4097788124653791), ('totale', 0.36402271921744017), ('nordeuropäischer', 0.3245318211921212), ('europäischsten', 0.3034649815059166), ('mitteleuropas', 0.30284411030505604)]\n",
      "iteration 7 done\n",
      "european: [('europäische', 0.9091283492552299), ('europäischen', 0.8763336355280662), ('europäischer', 0.8334983788663355), ('europäisches', 0.7678269979609829), ('europäisch', 0.5739611215219727), ('europawahlen', 0.41808388093231047), ('totale', 0.35012030157536994), ('nordeuropäischer', 0.3277368299331874), ('europäischsten', 0.30578646008952237), ('c5-0121', 0.30402760333565343)]\n",
      "iteration 8 done\n",
      "european: [('europäische', 0.9275740102913013), ('europäischen', 0.8967578921351563), ('europäischer', 0.8447033071254331), ('europäisches', 0.7754302356433546), ('europäisch', 0.5876414486407668), ('europawahlen', 0.42260232824263966), ('totale', 0.3349248976922489), ('nordeuropäischer', 0.3292853537691493), ('unionsbürgerschaft', 0.32641182700655275), ('c5-0121', 0.3152819097610976)]\n",
      "iteration 9 done\n"
     ]
    }
   ],
   "source": [
    "t_english_ger = EM(english_de_list, german_en_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization done\n",
      "european not found in the dictionary.\n",
      "iteration 0 done\n",
      "european not found in the dictionary.\n",
      "iteration 1 done\n",
      "european not found in the dictionary.\n",
      "iteration 2 done\n",
      "european not found in the dictionary.\n",
      "iteration 3 done\n",
      "european not found in the dictionary.\n",
      "iteration 4 done\n",
      "european not found in the dictionary.\n",
      "iteration 5 done\n",
      "european not found in the dictionary.\n",
      "iteration 6 done\n",
      "european not found in the dictionary.\n",
      "iteration 7 done\n",
      "european not found in the dictionary.\n",
      "iteration 8 done\n",
      "european not found in the dictionary.\n",
      "iteration 9 done\n"
     ]
    }
   ],
   "source": [
    "#t = EM(english_de_list, german_en_list)\n",
    "t_ger = EM(german_en_list, english_de_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and implement an algorithm to find a translation, given a sentence in the source language. That is, you should try to find\n",
    "E* = argmaxE P(E|F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translation of a sentence is calculated by product of sentence probability p(t) and the translation probability p(e|t)\n",
    "def translate_sentence(sentence, t, word_counter_bigrams, word_counter):\n",
    "    words = sentence.split(' ')\n",
    "    words = [word.lower() for word in words]\n",
    "\n",
    "    translated_sentence = []\n",
    "    translated_sentence.append('NULL')\n",
    "\n",
    "    for word in words:\n",
    "        probabilities = []\n",
    "        top_ten_translations = sorted(\n",
    "            [(key, inner_dict[word]) for key, inner_dict in t.items() if word in inner_dict],\n",
    "            key=lambda x: x[1],  # Sorting key based on the value (second element of the tuple)\n",
    "            reverse=True\n",
    "            )[:10]  # Selecting the top ten\n",
    "        #top_ten_translations = sorted(t[word].items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for word1, t_value in top_ten_translations:\n",
    "            temp_sentence = ' '.join(translated_sentence)\n",
    "            probabilities.append(probability_of_sentence(temp_sentence + ' ' + word1, word_counter_bigrams, word_counter)*t_value)\n",
    "        \n",
    "            #probabilities.append(value)\n",
    "            \n",
    "        translated_sentence.append(top_ten_translations[np.argmax(probabilities)][0])\n",
    "\n",
    "    return translated_sentence[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a european speaking here\n",
      "ich ich eine europäischen spreche hier\n",
      "A cat was here today and spoke about some things\n",
      "eine ausgeht wurde hier heute und gesprochen über einige dinge\n"
     ]
    }
   ],
   "source": [
    "#translating sentence with english as source language and german as target language\n",
    "german_en_word_counter_bigrams = count_bigrams(german_en_list)\n",
    "translation = translate_sentence('I am a european speaking here', t_ger, german_en_word_counter_bigrams, german_en_word_counter)\n",
    "translation = ' '.join(translation)\n",
    "print('I am a european speaking here')\n",
    "print(translation)\n",
    "translation = translate_sentence('A cat was here today and spoke about some things', t_ger, german_en_word_counter_bigrams, german_en_word_counter)\n",
    "translation = ' '.join(translation)\n",
    "print('A cat was here today and spoke about some things')\n",
    "print(translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
